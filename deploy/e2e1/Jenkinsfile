pipeline {
    agent any

    environment {
        NODEJS_HOME = tool 'NodeJS'
        PATH = "${NODEJS_HOME}/bin:${env.PATH}"
        REPORT_DIR = "${WORKSPACE}/reports"
        TEMP_DIR = "${WORKSPACE}/jest_temp"  // Set a new Jest temp directory
    }

    stages {
        stage("Install Node and Dependencies") {
            steps {
                script {
                    sh 'pnpm install'
                }
            }
        }

        stage("Prepare Test Batches") {
            steps {
                script {
                    echo "Collecting all test files..."
                    def testFiles = sh(
                        script: "find ${WORKSPACE}/test -name '*.e2e-spec.ts'",
                        returnStdout: true
                    ).trim().split("\n").findAll { it }

                    if (testFiles.isEmpty()) {
                        error "‚ùå No E2E test files found!"
                    }

                    int batchSize = 3
                    int batchCount = (testFiles.size() / batchSize) + ((testFiles.size() % batchSize) > 0 ? 1 : 0)

                    echo "Total Test Files: ${testFiles.size()}, Batches: ${batchCount}, Batch Size: ${batchSize}"

                    env.TEST_FILES_CSV = testFiles.join(',')
                    env.BATCH_SIZE = batchSize.toString()
                }
            }
        }

        stage("Run Test Batches") {
            steps {
                script {
                    sh "mkdir -p ${REPORT_DIR}"  // Ensure report directory exists
                    def testFiles = env.TEST_FILES_CSV.split(',')
                    int batchSize = env.BATCH_SIZE.toInteger()
                    def parallelStages = [:]

                    int numBatches = (testFiles.size() / batchSize) + ((testFiles.size() % batchSize) > 0 ? 1 : 0)

                    echo "Running ${numBatches} batches of tests..."

                    for (int i = 0; i < numBatches; i++) {
                        int start = i * batchSize
                        int end = Math.min((i + 1) * batchSize, testFiles.size())
                        def batchFiles = testFiles[start..<end].join(' ')
                        def batchReportDir = "${REPORT_DIR}/batch-${i + 1}"  // Unique report directory
                        def batchJsonReport = "${batchReportDir}/jest-results.json"

                        parallelStages["Batch-${i + 1}"] = {
                            script {
                                echo "Running Batch ${i + 1} with files: ${batchFiles}"

                                sh """
                                    mkdir -p '${batchReportDir}'
                                    export JEST_REPORT_DIR='${batchReportDir}'
                                    pnpm test:e2e --testPathPattern='${batchFiles.replaceAll(' ', '|')}' --json --outputFile='${batchJsonReport}'
                                """

                                // Extract Test Summary
                                def testSummary = sh(
                                    script: """
                                        passed=\$(grep -o '"numPassedTests":[0-9]*' '${batchJsonReport}' | awk -F ':' '{print \$2}')
                                        failed=\$(grep -o '"numFailedTests":[0-9]*' '${batchJsonReport}' | awk -F ':' '{print \$2}')
                                        echo "‚úÖ Passed: \${passed}, ‚ùå Failed: \${failed}"
                                        echo "PASSED_\${i+1}=\${passed}" >> env_vars.sh
                                        echo "FAILED_\${i+1}=\${failed}" >> env_vars.sh
                                    """,
                                    returnStdout: true
                                ).trim()

                                echo "testSummary**** ${testSummary}"
                            }
                        }
                    }

                    parallel parallelStages
                }
            }
        }
    }

    post {
        always {
            script {
                sh "ls -lhR ${REPORT_DIR} || echo '‚ùå No reports found!'" // Debugging step

                // Archive artifacts
                archiveArtifacts artifacts: 'reports/**', fingerprint: true

                // Jenkins Base URL
                def jenkinsBaseUrl = env.BUILD_URL // Gets the current build URL

                int totalPassed = 0
                int totalFailed = 0
                int totalPending = 0
                int totalSuites = 0

                // Generate report URLs dynamically
                def numBatches = env.BATCH_SIZE.toInteger()
                for (int i = 1; i <= numBatches; i++) {
                    def reportPath = "reports/batch-${i}/jest_report.html"
                    publishHTML([
                        reportName: "E2E Test Report - Batch ${i}",
                        reportDir: "reports/batch-${i}",
                        reportFiles: 'jest_report.html',
                        alwaysLinkToLastBuild: true,
                        keepAll: true
                    ])

                    // Print report URL in console
                    echo "üîó Report for Batch ${i}: ${jenkinsBaseUrl}artifact/${reportPath}"

                    def batchJsonReport = "${REPORT_DIR}/batch-${i}/jest-results.json"

                    if (fileExists(batchJsonReport)) {
                        echo "üìÇ Processing report: ${batchJsonReport}"
                        def jsonContent = readJSON text: readFile(batchJsonReport)

                        echo "JSON Content***: ${jsonContent}"
                        // def jsonContent = readJSON file: batchJsonReport

                        // totalPassed += jsonContent.numPassedTests
                        // totalFailed += jsonContent.numFailedTests
                        // totalPending += jsonContent.numPendingTests
                        // totalSuites += jsonContent.numTotalTestSuites
                    } else {
                        echo "‚ö†Ô∏è Warning: Report file not found for Batch ${i}"
                    }
                }

                echo "‚úÖ Total Passed: ${totalPassed}"
                echo "‚ùå Total Failed: ${totalFailed}"
                echo "‚è≥ Total Pending: ${totalPending}"
                echo "üóÇÔ∏è Total Test Suites: ${totalSuites}"
            }
        }

        success {
            echo "‚úÖ E2E Tests completed successfully!"
        }

        unstable {
            echo "‚ö†Ô∏è E2E Tests encountered issues but completed."
        }

        failure {
            echo "‚ùå E2E Tests failed! Check logs."
        }
    }
}
